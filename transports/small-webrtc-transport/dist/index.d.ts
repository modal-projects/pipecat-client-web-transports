import { PipecatClientOptions, RTVIEventCallbacks, Tracks, RTVIMessage, Transport, TransportState, APIRequest } from "@pipecat-ai/client-js";
import { DailyEventObjectTrack } from "@daily-co/daily-js";
declare abstract class MediaManager {
    protected _userAudioCallback: (data: ArrayBuffer) => void;
    protected _options: PipecatClientOptions;
    protected _callbacks: RTVIEventCallbacks;
    protected _micEnabled: boolean;
    protected _camEnabled: boolean;
    protected _supportsScreenShare: boolean;
    constructor();
    setUserAudioCallback(userAudioCallback: (data: ArrayBuffer) => void): void;
    setClientOptions(options: PipecatClientOptions, override?: boolean): void;
    abstract initialize(): Promise<void>;
    abstract connect(): Promise<void>;
    abstract disconnect(): Promise<void>;
    abstract userStartedSpeaking(): Promise<unknown>;
    abstract bufferBotAudio(data: ArrayBuffer | Int16Array, id?: string): Int16Array | undefined;
    abstract getAllMics(): Promise<MediaDeviceInfo[]>;
    abstract getAllCams(): Promise<MediaDeviceInfo[]>;
    abstract getAllSpeakers(): Promise<MediaDeviceInfo[]>;
    abstract updateMic(micId: string): void;
    abstract updateCam(camId: string): void;
    abstract updateSpeaker(speakerId: string): void;
    abstract get selectedMic(): MediaDeviceInfo | Record<string, never>;
    abstract get selectedCam(): MediaDeviceInfo | Record<string, never>;
    abstract get selectedSpeaker(): MediaDeviceInfo | Record<string, never>;
    abstract enableMic(enable: boolean): void;
    abstract enableCam(enable: boolean): void;
    abstract enableScreenShare(enable: boolean): void;
    abstract get isCamEnabled(): boolean;
    abstract get isMicEnabled(): boolean;
    abstract get isSharingScreen(): boolean;
    abstract tracks(): Tracks;
    get supportsScreenShare(): boolean;
}
export class WavMediaManager extends MediaManager {
    constructor(recorderChunkSize?: number | undefined, recorderSampleRate?: number | undefined);
    initialize(): Promise<void>;
    connect(): Promise<void>;
    disconnect(): Promise<void>;
    userStartedSpeaking(): Promise<unknown>;
    bufferBotAudio(data: ArrayBuffer | Int16Array, id?: string): Int16Array;
    getAllMics(): Promise<MediaDeviceInfo[]>;
    getAllCams(): Promise<MediaDeviceInfo[]>;
    getAllSpeakers(): Promise<MediaDeviceInfo[]>;
    updateMic(micId: string): Promise<void>;
    updateCam(camId: string): void;
    updateSpeaker(speakerId: string): void;
    get selectedMic(): MediaDeviceInfo | Record<string, never>;
    get selectedCam(): MediaDeviceInfo | Record<string, never>;
    get selectedSpeaker(): MediaDeviceInfo | Record<string, never>;
    enableMic(enable: boolean): Promise<void>;
    enableCam(enable: boolean): void;
    enableScreenShare(enable: boolean): void;
    get isCamEnabled(): boolean;
    get isMicEnabled(): boolean;
    get isSharingScreen(): boolean;
    tracks(): Tracks;
}
export class DailyMediaManager extends MediaManager {
    constructor(enablePlayer?: boolean, enableRecording?: boolean, onTrackStartedCallback?: (event: DailyEventObjectTrack) => void, onTrackStoppedCallback?: (event: DailyEventObjectTrack) => void, recorderChunkSize?: number | undefined, recorderSampleRate?: number, playerSampleRate?: number);
    initialize(): Promise<void>;
    connect(): Promise<void>;
    disconnect(): Promise<void>;
    userStartedSpeaking(): Promise<unknown>;
    bufferBotAudio(data: ArrayBuffer | Int16Array, id?: string): Int16Array | undefined;
    getAllMics(): Promise<MediaDeviceInfo[]>;
    getAllCams(): Promise<MediaDeviceInfo[]>;
    getAllSpeakers(): Promise<MediaDeviceInfo[]>;
    updateMic(micId: string): void;
    updateCam(camId: string): void;
    updateSpeaker(speakerId: string): Promise<void>;
    get selectedMic(): MediaDeviceInfo | Record<string, never>;
    get selectedCam(): MediaDeviceInfo | Record<string, never>;
    get selectedSpeaker(): MediaDeviceInfo | Record<string, never>;
    enableMic(enable: boolean): Promise<void>;
    enableCam(enable: boolean): void;
    enableScreenShare(enable: boolean): void;
    get isCamEnabled(): boolean;
    get isMicEnabled(): boolean;
    get isSharingScreen(): boolean;
    tracks(): Tracks;
    protected handleTrackStarted(event: DailyEventObjectTrack): Promise<void>;
    protected handleTrackStopped(event: DailyEventObjectTrack): void;
}
declare class TrackStatusMessage {
    type: string;
    receiver_index: number;
    enabled: boolean;
    constructor(receiver_index: number, enabled: boolean);
}
export type IceConfig = {
    iceServers?: RTCIceServer[];
};
export type SmallWebRTCTransportConnectionOptions = {
    /** @deprecated Use webrtcRequestParams instead */
    connectionUrl?: string;
    /** @deprecated Use webrtcRequestParams instead */
    webrtcUrl?: string;
    webrtcRequestParams?: APIRequest;
    iceConfig?: IceConfig;
};
export interface SmallWebRTCTransportConstructorOptions extends SmallWebRTCTransportConnectionOptions {
    iceServers?: RTCIceServer[];
    waitForICEGathering?: boolean;
    audioCodec?: string;
    videoCodec?: string;
    mediaManager?: MediaManager;
}
declare class RenegotiateMessage {
    type: string;
}
declare class PeerLeftMessageMessage {
    type: string;
}
type OutboundSignallingMessage = TrackStatusMessage;
type InboundSignallingMessage = RenegotiateMessage | PeerLeftMessageMessage;
declare const SIGNALLING_TYPE = "signalling";
declare class SignallingMessageObject {
    type: typeof SIGNALLING_TYPE;
    message: InboundSignallingMessage | OutboundSignallingMessage;
    constructor(message: InboundSignallingMessage | OutboundSignallingMessage);
}
/**
 * SmallWebRTCTransport is a class that provides a client-side
 * interface for connecting to the SmallWebRTCTransport provided by Pipecat
 */
export class SmallWebRTCTransport extends Transport {
    static SERVICE_NAME: string;
    constructor(opts?: SmallWebRTCTransportConstructorOptions);
    initialize(options: PipecatClientOptions, messageHandler: (ev: RTVIMessage) => void): void;
    initDevices(): Promise<void>;
    setAudioCodec(audioCodec: string | null): void;
    setVideoCodec(videoCodec: string | null): void;
    _resolveRequestInfo(params: SmallWebRTCTransportConstructorOptions | SmallWebRTCTransportConnectionOptions): APIRequest | null;
    _getStartEndpointAsString(): string | undefined;
    _validateConnectionParams(connectParams: unknown): SmallWebRTCTransportConnectionOptions | undefined;
    _connect(connectParams?: SmallWebRTCTransportConnectionOptions): Promise<void>;
    sendReadyMessage(): void;
    sendMessage(message: RTVIMessage): void;
    _disconnect(): Promise<void>;
    handleMessage(message: string): void;
    handleSignallingMessage(messageObj: SignallingMessageObject): Promise<void>;
    getAllMics(): Promise<MediaDeviceInfo[]>;
    getAllCams(): Promise<MediaDeviceInfo[]>;
    getAllSpeakers(): Promise<MediaDeviceInfo[]>;
    updateMic(micId: string): Promise<void>;
    updateCam(camId: string): void;
    updateSpeaker(speakerId: string): void;
    get selectedMic(): MediaDeviceInfo | Record<string, never>;
    get selectedCam(): MediaDeviceInfo | Record<string, never>;
    get selectedSpeaker(): MediaDeviceInfo | Record<string, never>;
    set iceServers(iceServers: RTCIceServer[]);
    get iceServers(): RTCIceServer[];
    enableMic(enable: boolean): void;
    enableCam(enable: boolean): void;
    enableScreenShare(enable: boolean): Promise<void>;
    get isCamEnabled(): boolean;
    get isMicEnabled(): boolean;
    get isSharingScreen(): boolean;
    get state(): TransportState;
    set state(state: TransportState);
    tracks(): Tracks;
}

//# sourceMappingURL=index.d.ts.map
